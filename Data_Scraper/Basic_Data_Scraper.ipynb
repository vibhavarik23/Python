{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dfb76b4",
   "metadata": {},
   "source": [
    "Step 1: Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee3af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114b4ae4",
   "metadata": {},
   "source": [
    "#### Step 2: Send an HTTP request to the website\n",
    "\n",
    "Use the requests library to send an HTTP GET request to the website you want to scrape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a01790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request successful!\n"
     ]
    }
   ],
   "source": [
    "url=\"https://en.wikipedia.org/wiki/Python_(programming_language)\"\n",
    "response=requests.get(url)\n",
    "\n",
    "if response.status_code==200:\n",
    "    print(\"Request successful!\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d388035",
   "metadata": {},
   "source": [
    "#### Step 3: Parse the HTML content\n",
    "Once you’ve successfully retrieved the web page, use BeautifulSoup to parse the HTML content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84041b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python (programming language) - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "# Print the title of the webpage to verify\n",
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2808e88",
   "metadata": {},
   "source": [
    "#### Step 4: Extract the data you need\n",
    "Now that you have the HTML parsed, you can start extracting the data you’re interested in. Let’s say you want to scrape a list of items from a table on the web page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0733e968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Type Mutability  \\\n",
      "0                       None       None   \n",
      "1                       bool  immutable   \n",
      "2                  bytearray    mutable   \n",
      "3                      bytes  immutable   \n",
      "4                    complex  immutable   \n",
      "5                       dict    mutable   \n",
      "6         types.EllipsisType  immutable   \n",
      "7                      float  immutable   \n",
      "8                  frozenset  immutable   \n",
      "9                        int  immutable   \n",
      "10                      list    mutable   \n",
      "11            types.NoneType  immutable   \n",
      "12  types.NotImplementedType  immutable   \n",
      "13                     range  immutable   \n",
      "14                       set    mutable   \n",
      "15                       str  immutable   \n",
      "16                     tuple  immutable   \n",
      "\n",
      "                                          Description  \\\n",
      "0                                                None   \n",
      "1                                       Boolean value   \n",
      "2                                   Sequence of bytes   \n",
      "3                                   Sequence of bytes   \n",
      "4        Complex number with real and imaginary parts   \n",
      "5   Associative array (or dictionary) of key and v...   \n",
      "6   An ellipsis placeholder to be used as an index...   \n",
      "7   Double-precision floating-point number. The pr...   \n",
      "8   Unordered set, contains no duplicates; can con...   \n",
      "9                 Integer of unlimited magnitude[120]   \n",
      "10                      List, can contain mixed types   \n",
      "11  An object representing the absence of a value,...   \n",
      "12  A placeholder that can be returned from overlo...   \n",
      "13  An immutable sequence of numbers commonly used...   \n",
      "14  Unordered set, contains no duplicates; can con...   \n",
      "15  A character string: sequence of Unicode codepo...   \n",
      "16                            Can contain mixed types   \n",
      "\n",
      "                                      Syntax examples  \n",
      "0                                                None  \n",
      "1                                           TrueFalse  \n",
      "2   bytearray(b'Some ASCII')bytearray(b\"Some ASCII...  \n",
      "3   b'Some ASCII'b\"Some ASCII\"bytes([119, 105, 107...  \n",
      "4                                      3+2.7j3 + 2.7j  \n",
      "5                           {'key1': 1.0, 3: False}{}  \n",
      "6                                         ...Ellipsis  \n",
      "7                                             1.33333  \n",
      "8                    frozenset([4.0, 'string', True])  \n",
      "9                                                  42  \n",
      "10                            [4.0, 'string', True][]  \n",
      "11                                               None  \n",
      "12                                     NotImplemented  \n",
      "13                     range(−1, 10)range(10, −5, −2)  \n",
      "14                         {4.0, 'string', True}set()  \n",
      "15  'Wikipedia'\"Wikipedia\"\"\"\"Spanning\\nmultiple\\nl...  \n",
      "16         (4.0, 'string', True)('single element',)()  \n"
     ]
    }
   ],
   "source": [
    "# Find the table containing the data\n",
    "table = soup.find('table', class_='wikitable')  # Replace 'data-table' with the actual id or class of the table\n",
    "\n",
    "# Extract table rows\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# Loop through the rows and extract data\n",
    "data = []\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    cols = [col.text.strip() for col in cols]\n",
    "    data.append(cols)\n",
    "\n",
    "# Convert the data into a pandas DataFrame for easier manipulation\n",
    "df = pd.DataFrame(data, columns=['Type','Mutability','Description','Syntax examples'])  # Replace with actual column names\n",
    "\n",
    "# Display the scraped data\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34149d9d",
   "metadata": {},
   "source": [
    "#### Step 5: Save the scraped data\n",
    "Finally, you can save the scraped data to a file for further analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f62a53ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Wiki_data_scraped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d721e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
